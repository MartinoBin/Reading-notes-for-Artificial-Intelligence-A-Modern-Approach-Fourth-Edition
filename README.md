# Reading-notes-for-Artificial-Intelligence-A-Modern-Approach-Fourth-Edition

Weekly summary report 1
I read 1.1 and 1.2 of chapter 1 (the 4th Global Edition). It discusses two questions: What is AI and what are the foundations of AI. The book has provided many basic concepts from the very beginning, such as the Turing test, automated reasoning, and machine learning. For someone like me who is new to this area, all the terms need to be read and studied carefully.  I have to say, it takes time.

In terms of the foundations of AI in 1.2, I'm particularly not familiar with the control theory and cybernetics.  This is not to say that I'm quite familiar with the other 7 foundations of course, but at least we could hear some words quite frequently mentioned from the daily environment. Therefore, I expect more discussion on this control theory topic.

One impression that I had when I was reading 1.2: it says philosophy is the first foundation of AI, then mathematics, then economics...etc. For me, the boundaries between these areas are not easy to distinguish, especially when it comes to the top of the interdisciplinary area, each case can be different, from a self-driving car to a customer service chat robot. It is interesting to read that linguistic and Noam Chomsky is mentioned. Comparing with the most important contributors in the other AI foundations, he seems to be the only one who is mentioned as a linguist. However, I always think he is a philosopher first, then a mathematician, and then a social activist. Therefore, I put a question mark on how syntax and grammar can help to shape some AI areas such as NLP (natural language processing).

Another thing I particularly found impressive, in 1.3.6 it says: '(from 1987 onwards) The brittleness of expert systems led to a new, more scientific approach incorporating probability rather than Boolean logic, machine learning rather than hand-coding, and experimental results rather than philosophical claims.'  (p.42) Making philosophical claims more than pursuing experiment results. This is exactly my impression of the modern 2020 linguists! Maybe this is why Chomsky is the only one who left can be mentioned in AI foundation as a linguist.  

In order to finish the first quizzes, I spent some time figuring out the relation between computer science, AI, machine learning, and deep learning. It is good to slow down and think about what exactly are they and what's the difference among them. I also read the elements of Ai online course part 1, but I'm still not sure, for example, what areas can be involved in driving a taxi in a real environment? I would say all. It depends on how complicated the product is supposed to be. So I think the questions are a little tricky in terms of how do we interpret them, or it needs to be more specific. Therefore I expect some clarification next lesson. I think I need to finish reading the entire 1.3 in order to have a general sense.

Some references seem not easy to find at the end of the book. For example, this Marvin Minsky (1969) in chapter 1.3 (p.35) seems not to list in the references. Did I miss something?

Around 10 hours. 



Weekly summary report 2
The reading task for this week is 1.3 The History of Artificial Intelligence. (and maybe 1.4 and 1.5 )

The introduction goes from Marvin Minsky (1969) and John McCarthy (1971) to Geoffrey Hinton's team who won the 2012 ImageNet competition. The early milestones have been mentioned such as Hebbian learning and SNARCI in the 1950s. Then the great expectations around the 1950s to 1960s happened and then slowed down and found out there were realities that the researchers had to face, which lead to the realization that AI study still has a lot of limitations. 

This leads to the discussion of so-called 'winters'. As far as I think, there are no so-called two or three 'winters', if view it from an even longer time scale. The enthusiasm and fade happened all the time and probably in all the subjects. I happened to know that in around the 1970s, a bunch of British language researchers, or grammarians, gathered in London and started a project to make a language database, which is later called corpus or corpora, and then it become the foundation of the subject that today we called corpus linguistics. It is also around this enthusiasm period, they thought that the language database can do everything, particularly in studying English grammar and syntax.

This fact makes it very interesting to read that on page p.41 Schank says 'there is no such thing as syntax.' Because Norm Chomsky also said similar words in terms of corpus linguistics: ' There is no such thing called corpus linguistics.'  He made this comment after the enthusiasm grammarians have claimed that it was the 'spring' of corpus linguistics as a subject. 

I spent part of my time doing quiz and getting myself more familiar with the cases mentioned in the chapter. Comparing with 1.1 and 1.2, this 1.3 contains much fewer new terms. 1.4 gives some applications of AI today, which most of them can be searched on youtube. 1.5 discusses the risk and benefits of AI. Two questions that need to keep in mind are the Gorilla problem and King Midas problem. 

I'm still thinking about the meaning of this sentence:

"The fact that a program can find a solution in principle does not mean that the program contains any of the mechanisms needed to find it in practice. " p.39

 I don't understand what does this '...needed to find it in practice.' means.  

Roughly 5 hours.


Weekly summary report 3
The reading for this week is chapter 2 Intelligent agents. From 2.1 to 2.4, basically the entire chapter. I feel this is still an introduction to AI following the pace of the previous chapter. It covers the structure of agents and the nature of environments. For me, the first half part (2.1 to 2.3) is fine to follow, but the second half (2.4, I am using the 4th edition ) is a bit difficult to follow. 

At the beginning of the chapter, 2.1 Agents and Environments introduced how the relation between agents and environments can be built through sensors and actuators. It used a clear example, the vacuum cleaner world to demonstrate how the sensors and actuators work in order to complete the task. It leads to a question: What is the right way to fill out the task area? The picture on page 56 [Figure 2.2] gives a clear and simple picture of the concept.

Chapter 2.2 mainly talks about performance measures and rationality. An important point that I learned from this chapter is '' that rationality is not the same as perfection" (p.59). An interesting case is mentioned at the bottom of page 58. If a man walks through the empty street in order to say hello to a friend, and then was flattened by a dropped airline cargo door, is this because he was too irrational? (This example is partly based on real news back to 1989 ). 

Chapter 2.3 The Nature of Environments introduced different task environments. In order to design a good and suitable agent, we need to figure out what kind of environments the tasks will be carried out with. For example, it is fully observable or partially observable, is it single agent or multi-agent?  Some examples are given in the form of tables from Figure 2.4 to 2.6. Combining with the quiz assignment, I can feel that I am getting familiar with these concepts and gradually began to distinguish them by putting them into examples. 

Chapter 2.4 is a bit difficult for me. I feel the style of writing has just changed, or the contents in this chapter are not really extended in a way that is combined with enough real-life examples. It introduced different agents, simple reflex agents, model-based reflex agents, goal-based agents, utility-based agents. The charts [from Figure 2.9-2.15] are similar to each other at the first glance. The concepts are abstractive, especially when it comes to such words as condition-action rules, goals, utility, learning elements. What exactly are they if put them into a real environment or real case? It might take me more time to figure this out. 

The lecture video, which mentioned problem-solving, seems not in this weeks materials. I didn't manage to find any content involved with problem-solving. My feeling is that this is for chapter 3, which I haven't read.  

Roughly 6 hours
